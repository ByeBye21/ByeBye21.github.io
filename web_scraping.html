<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Scraping Automation</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-100 font-sans text-gray-800">
    <!-- Navigation Bar -->
    <nav class="bg-white shadow-md fixed w-full z-10">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between h-16">
                <div class="flex items-center">
                    <span class="text-2xl font-bold text-indigo-600">CodeFlow</span>
                </div>
                <div class="flex items-center space-x-4">
                    <a href="index.html#home" class="text-gray-600 hover:text-indigo-600 px-3 py-2 rounded-md text-sm font-medium">Home</a>
                    <a href="index.html#projects" class="text-gray-600 hover:text-indigo-600 px-3 py-2 rounded-md text-sm font-medium">Projects</a>
                    <a href="index.html#about" class="text-gray-600 hover:text-indigo-600 px-3 py-2 rounded-md text-sm font-medium">About</a>
                    <a href="index.html#contact" class="text-gray-600 hover:text-indigo-600 px-3 py-2 rounded-md text-sm font-medium">Contact</a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Project Details -->
    <section class="py-20 pt-24">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <h1 class="text-3xl font-bold mb-6">Web Scraping Automation</h1>
            <img src="images/web_scraping.png" alt="Web Scraping Automation" class="mb-6 w-full h-64 object-cover rounded-lg">
            <p class="text-lg text-gray-600 mb-6">This Python script automates data extraction from websites using Selenium and BeautifulSoup. 
                It collects structured data (e.g., product details, prices) and saves it to a CSV file for analysis.
            </p>
                <h2 class="text-2xl font-bold mb-4">Features</h2>
                <ul class="list-disc list-inside mb-6">
                    <li>Navigates dynamic websites with JavaScript-rendered content.</li>
                    <li>Extracts specific data using CSS selectors or XPath.</li>
                    <li>Saves scraped data to CSV or JSON formats.</li>
                    <li>Handles pagination and rate limiting.</li>
                </ul>
                <h2 class="text-2xl font-bold mb-4">Technologies Used</h2>
                <ul class="list-disc list-inside mb-6">
                    <li>Python</li>
                    <li>Selenium for browser automation</li>
                    <li>BeautifulSoup for HTML parsing</li>
                    <li>Pandas for data processing</li>
                </ul>
                <h2 class="text-2xl font-bold mb-4">Code Snippet</h2>
                <pre class="bg-gray-200 p-4 rounded"><code>
                        from selenium import webdriver
                        from bs4 import BeautifulSoup
                        import pandas as pd
                        
                        def scrape_website(url):
                            driver = webdriver.Chrome()
                            driver.get(url)
                            soup = BeautifulSoup(driver.page_source, 'html.parser')
                            
                            items = soup.select('.product-item')
                            data = []
                            for item in items:
                                name = item.select_one('.name').text
                                price = item.select_one('.price').text
                                data.append({'name': name, 'price': price})
                            
                            df = pd.DataFrame(data)
                            df.to_csv('products.csv', index=False)
                            driver.quit()
                        
                        scrape_website('https://example.com')
            </code></pre>
            <p class="text-lg text-gray-600 mb-6">
                Note: Replace <code>https://example.com</code> with the target website and adjust selectors as needed.
            </p>
            <a href="https://github.com/ByeBye21/web-scraping" class="text-indigo-600 hover:underline">View on GitHub</a>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-800 text-white py-6">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
            <p>Â© 2025 ByeBye21. All rights reserved.</p>
            <div class="mt-4 flex justify-center space-x-4">
                <a href="https://github.com/ByeBye21" class="hover:text-indigo-400">GitHub</a>
                <a href="https://www.linkedin.com/in/younes-rahebi-0089ab293/" class="hover:text-indigo-400">LinkedIn</a>
            </div>
        </div>
    </footer>
</body>
</html>
